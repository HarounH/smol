{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuArPKaVDh8MHS3+Luy3C4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarounH/smol/blob/main/rl/distributed_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LmS00ih05hom",
        "outputId": "b5f58b19-5050-4ab9-faed-85a812e47da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]\n",
            "Array [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "Device TFRT_CPU_0\n",
            "Sharding SingleDeviceSharding(device=CpuDevice(id=0), memory_kind=device)\n",
            "Mesh('i': 8, axis_types=(Auto,))\n",
            "Sharded array [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
            "Device {CpuDevice(id=6), CpuDevice(id=0), CpuDevice(id=3), CpuDevice(id=1), CpuDevice(id=7), CpuDevice(id=5), CpuDevice(id=2), CpuDevice(id=4)}\n",
            "Sharding NamedSharding(mesh=Mesh('i': 8, axis_types=(Auto,)), spec=PartitionSpec('i',), memory_kind=device)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107mCPU 1\u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82mCPU 2\u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 3\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148mCPU 4\u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207mCPU 5\u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148mCPU 6\u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49mCPU 7\u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m  \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;214;97;107m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;162;82m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;0;0;0;48;2;231;203;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;107;110;207m         \u001b[0m\u001b[38;2;255;255;255;48;2;165;81;148m         \u001b[0m\u001b[38;2;255;255;255;48;2;140;109;49m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">  CPU 0  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">  CPU 1  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">  CPU 2  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">  CPU 3  </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">  CPU 4  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">  CPU 5  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">  CPU 6  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">  CPU 7  </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #d6616b\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8ca252\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #e7cb94\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #6b6ecf\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #a55194\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #8c6d31\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set this to True to run the model on CPU only.\n",
        "USE_CPU_ONLY = True\n",
        "\n",
        "flags = os.environ.get(\"XLA_FLAGS\", \"\")\n",
        "if USE_CPU_ONLY:\n",
        "    flags += \" --xla_force_host_platform_device_count=8\"  # Simulate 8 devices\n",
        "    # Enforce CPU-only execution\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "else:\n",
        "    # GPU flags\n",
        "    flags += (\n",
        "        \"--xla_gpu_enable_triton_softmax_fusion=true \"\n",
        "        \"--xla_gpu_triton_gemm_any=false \"\n",
        "        \"--xla_gpu_enable_async_collectives=true \"\n",
        "        \"--xla_gpu_enable_latency_hiding_scheduler=true \"\n",
        "        \"--xla_gpu_enable_highest_priority_async_stream=true \"\n",
        "    )\n",
        "os.environ[\"XLA_FLAGS\"] = flags\n",
        "import functools\n",
        "from typing import Any, Dict, Tuple\n",
        "\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from jax.experimental.shard_map import shard_map\n",
        "from jax.sharding import Mesh, NamedSharding\n",
        "from jax.sharding import PartitionSpec as P\n",
        "\n",
        "PyTree = Any\n",
        "Metrics = Dict[str, Tuple[jax.Array, ...]]\n",
        "\n",
        "print(jax.devices())\n",
        "\n",
        "a = jnp.arange(16)\n",
        "print(\"Array\", a)\n",
        "print(\"Device\", a.device)\n",
        "print(\"Sharding\", a.sharding)\n",
        "\n",
        "mesh = Mesh(np.array(jax.devices()), (\"i\",))\n",
        "print(mesh)\n",
        "\n",
        "sharding = NamedSharding(\n",
        "    mesh,\n",
        "    P(\"i\"),\n",
        ")\n",
        "\n",
        "a_sharded = jax.device_put(a, sharding)\n",
        "print(\"Sharded array\", a_sharded)\n",
        "print(\"Device\", a_sharded.devices())\n",
        "print(\"Sharding\", a_sharded.sharding)\n",
        "jax.debug.visualize_array_sharding(a_sharded)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l0zpPm3JnNi7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}