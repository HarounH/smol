{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl2S0pQAlbDgy9vZdvi8dz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarounH/smol/blob/main/rl/policy_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install dependencies\n",
        "!pip install rarfile\n",
        "!pip install ale-py\n",
        "!pip install -q gymnasium\n",
        "!pip install swig\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install pyglet\n",
        "!pip install pygame\n",
        "!pip install minigrid\n",
        "!pip install -q swig\n",
        "!pip install minigrid\n",
        "!pip3 install box2d-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ8hppjwg0ud",
        "outputId": "d7968d0e-776b-4e94-d3b4-c7e8ba0ab1a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n",
            "Requirement already satisfied: ale-py in /usr/local/lib/python3.12/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.12/dist-packages (from ale-py) (2.0.2)\n",
            "Collecting swig\n",
            "  Downloading swig-4.4.0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.4.0-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.4.0\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Collecting pyglet\n",
            "  Downloading pyglet-2.1.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Downloading pyglet-2.1.11-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyglet\n",
            "Successfully installed pyglet-2.1.11\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Collecting minigrid\n",
            "  Downloading minigrid-3.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from minigrid) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from minigrid) (1.2.2)\n",
            "Requirement already satisfied: pygame>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from minigrid) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (0.0.4)\n",
            "Downloading minigrid-3.0.0-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.7/136.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: minigrid\n",
            "Successfully installed minigrid-3.0.0\n",
            "Requirement already satisfied: minigrid in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from minigrid) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from minigrid) (1.2.2)\n",
            "Requirement already satisfied: pygame>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from minigrid) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium>=0.28.1->minigrid) (0.0.4)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp312-cp312-linux_x86_64.whl size=2399002 sha256=d67119f087cb3e58c167cafa79fa2716fa396dcbd6f83fb58f9ff3d32153fac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/3c/ab/b6fd75459cadc56f4a4125d4cb387a708a59ca8589e4cc6b7d\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iYA96SYpT2Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168e02e6-8d15-4576-ccf8-51d999a2b098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1147357637.py:24: DeprecationWarning: Please import `gaussian_filter1d` from the `scipy.ndimage` namespace; the `scipy.ndimage.filters` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  from scipy.ndimage.filters import gaussian_filter1d\n"
          ]
        }
      ],
      "source": [
        "# @title Environment Set up and Rendering\n",
        "\n",
        "import gymnasium\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from dataclasses import dataclass\n",
        "import io\n",
        "import base64\n",
        "import optax\n",
        "\n",
        "import numpy as np\n",
        "import imageio.v2 as imageio\n",
        "from IPython.display import HTML\n",
        "import jax.numpy as jnp\n",
        "from flax import struct\n",
        "import jax\n",
        "\n",
        "from IPython.display import HTML\n",
        "import numpy as np\n",
        "import imageio\n",
        "import io, base64\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import time\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "import orbax.checkpoint as ocp\n",
        "from flax import nnx\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "@struct.dataclass\n",
        "class Datum:\n",
        "    s_t: jax.Array\n",
        "    s_tp1: jax.Array\n",
        "    r_t: jax.Array\n",
        "    a_t: jax.Array\n",
        "    logp_a_t: jax.Array | None\n",
        "    done: bool\n",
        "    on_policy_t: bool\n",
        "    frame_hwc: np.ndarray | None = None\n",
        "\n",
        "\n",
        "def show_mp4_from_frames_imageio(\n",
        "    trajectory: list[Datum],\n",
        "    text_color=(255, 0, 0), # red\n",
        "    text_padding=10,\n",
        "    fps=30,\n",
        "):\n",
        "    \"\"\"\n",
        "    Display a list of (H, W, 3) RGB frames inline as MP4 with optional per-frame text.\n",
        "\n",
        "    Args:\n",
        "        frames: list of frames, each (H, W, 3), RGB.\n",
        "        fps: frames per second.\n",
        "        text: either a single string or list of strings (len == len(frames)).\n",
        "        text_color: RGB tuple for text.\n",
        "        text_padding: pixels offset from top-right corner.\n",
        "\n",
        "    Returns:\n",
        "        IPython.display.HTML object.\n",
        "    \"\"\"\n",
        "    frames = [d.frame_hwc for d in trajectory if d.frame_hwc is not None]\n",
        "    text = [f\"a:{d.a_t}\" for d in trajectory]\n",
        "    if not frames:\n",
        "        raise ValueError(\"frames list is empty\")\n",
        "\n",
        "    # Normalize text argument\n",
        "    if text is None:\n",
        "        texts = [None] * len(frames)\n",
        "    elif isinstance(text, str):\n",
        "        texts = [text] * len(frames)\n",
        "    else:\n",
        "        if len(text) != len(frames):\n",
        "            raise ValueError(\"text list must be same length as frames\")\n",
        "        texts = text\n",
        "\n",
        "    norm_frames = []\n",
        "    for idx, f in enumerate(frames):\n",
        "        f = np.asarray(f)\n",
        "\n",
        "        if f.ndim != 3 or f.shape[-1] != 3:\n",
        "            raise ValueError(f\"Frame must be (H,W,3), got {f.shape}\")\n",
        "\n",
        "        # Normalize dtype → uint8\n",
        "        if f.dtype != np.uint8:\n",
        "            if np.issubdtype(f.dtype, np.floating):\n",
        "                f = np.clip(f, 0.0, 1.0)\n",
        "                f = (f * 255).astype(np.uint8)\n",
        "            else:\n",
        "                f = np.clip(f, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Convert to PIL for text overlay\n",
        "        img = Image.fromarray(f)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        txt = texts[idx]\n",
        "        if txt:\n",
        "            # Choose a default font\n",
        "            try:\n",
        "                font = ImageFont.truetype(\"DejaVuSans.ttf\", 20)\n",
        "            except:\n",
        "                font = ImageFont.load_default()\n",
        "\n",
        "            # Width via textlength\n",
        "            tw = draw.textlength(txt, font=font)\n",
        "            # Height via font metrics\n",
        "            ascent, descent = font.getmetrics()\n",
        "            th = ascent + descent\n",
        "            # Position: top-right\n",
        "            H, W = f.shape[:2]\n",
        "            x = W - tw - text_padding\n",
        "            y = text_padding\n",
        "\n",
        "            draw.text((x, y), txt, fill=text_color, font=font)\n",
        "\n",
        "        norm_frames.append(np.asarray(img))\n",
        "\n",
        "    # Encode MP4 into an in-memory buffer\n",
        "    buf = io.BytesIO()\n",
        "    imageio.mimsave(buf, norm_frames, format=\"mp4\", fps=fps)\n",
        "    buf.seek(0)\n",
        "    video_bytes = buf.read()\n",
        "\n",
        "    b64 = base64.b64encode(video_bytes).decode(\"ascii\")\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <video controls loop>\n",
        "        <source src=\"data:video/mp4;base64,{b64}\" type=\"video/mp4\">\n",
        "        Your browser does not support the video tag.\n",
        "    </video>\n",
        "    \"\"\"\n",
        "    return HTML(html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
        "def play(\n",
        "    policy_model,\n",
        "    exploration_probability: float,\n",
        "    env,\n",
        "    current_state,\n",
        "    rng,\n",
        "    greedy: bool = True,\n",
        "    render: bool = False,\n",
        ") -> tuple[Datum, np.ndarray]:\n",
        "    action = env.action_space.sample()\n",
        "    logp_a_t = None\n",
        "    on_policy_t = False\n",
        "    if (policy_model is not None):\n",
        "        if (jax.random.bernoulli(rng.params(), exploration_probability, shape=None)):\n",
        "            pass\n",
        "        else:\n",
        "            pi_a = policy_model(current_state)\n",
        "            logp_a_t = pi_a\n",
        "            if greedy:\n",
        "                action = pi_a.argmax()\n",
        "            else:\n",
        "                action = jax.random.multinomial(rng.params(), 1, jax.nn.softmax(pi_a))\n",
        "            on_policy_t = True\n",
        "\n",
        "    frame_hwc = env.render() if render else None\n",
        "    new_state, reward, t0, t1, _ = env.step(action)\n",
        "    done = (t0 or t1)\n",
        "    datum = Datum(\n",
        "        s_t=current_state,\n",
        "        s_tp1=new_state,\n",
        "        r_t=reward,\n",
        "        a_t=action,\n",
        "        logp_a_t=logp_a_t,\n",
        "        done=done,\n",
        "        on_policy_t=on_policy_t,\n",
        "        frame_hwc=frame_hwc,\n",
        "    )\n",
        "    return datum, new_state\n",
        "\n",
        "\n",
        "def demo(model=None):\n",
        "    n_steps = 100\n",
        "    trajectory = []\n",
        "    rngs = nnx.Rngs(default=1337)\n",
        "    state, _ = env.reset()\n",
        "    for step_idx in range(n_steps):\n",
        "        datum, state = play(model, 0.0, env, state, rngs, greedy=False, render=True)\n",
        "        trajectory.append(datum)\n",
        "    return trajectory\n",
        "\n",
        "show_mp4_from_frames_imageio(demo(None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "_1mhMODcgxcJ",
        "outputId": "08dfc60f-7592-4fbd-da59-6e269694f680"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/box2d/lunar_lander.py:672: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Frame must be (H,W,3), got ()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1498677027.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mshow_mp4_from_frames_imageio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1147357637.py\u001b[0m in \u001b[0;36mshow_mp4_from_frames_imageio\u001b[0;34m(frames, text, text_color, text_padding, fps)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Frame must be (H,W,3), got {f.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Normalize dtype → uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Frame must be (H,W,3), got ()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model\n",
        "\n",
        "class Layer(nnx.Module):\n",
        "    def __init__(self, dim: int, rngs: nnx.Rngs):\n",
        "        self.fc1 = nnx.Linear(dim, dim, rngs=rngs)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        z = self.fc1(x)\n",
        "        z = jax.nn.relu(z)\n",
        "        return z\n",
        "\n",
        "\n",
        "class PolicyNetwork(nnx.Module):\n",
        "    # same shape and stuff as QNet\n",
        "    def __init__(self, dim_in: int = 4, d_model: int = 32, num_actions: int = 2, num_layers: int = 2, rngs: nnx.Rngs | None = None):\n",
        "        self.in_proj = nnx.Linear(dim_in, d_model, rngs=rngs)\n",
        "        self.out_proj = nnx.Linear(d_model, num_actions, rngs=rngs)\n",
        "        self.layers = [Layer(d_model, rngs) for _layer_idx in range(num_layers)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        z = self.in_proj(x)\n",
        "        for layer in self.layers:\n",
        "            z = layer(z)\n",
        "        z = self.out_proj(z)\n",
        "        return z\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ws5erLDK3ikJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Policy gradients - REINFORCE\n",
        "\"\"\"\n",
        "J(\\theta) = \\mathbb{E}_{\\tau~\\pi}[reward(\\tau)]\n",
        "\n",
        "after taking gradient, we get this interesting form:\n",
        "\\grad_{\\theta} J(\\theta) = \\mathbb{E}_{\\tau~\\pi}[Q(s, a) \\grad ln(\\pi(a | s))]\n",
        "\"\"\"\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "\n",
        "@struct.dataclass\n",
        "class Hyperparams:\n",
        "    num_training_episodes: int\n",
        "    max_episode_length: int\n",
        "\n",
        "    seed: int = 1337\n",
        "    explore_start = 1.0            # exploration probability at start\n",
        "    explore_stop = 0.01            # minimum exploration probability\n",
        "    decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
        "\n",
        "\n",
        "@struct.dataclass\n",
        "class TensorTrajectory:\n",
        "    s_t_TD: jax.Array\n",
        "    s_tp1_TD: jax.Array\n",
        "    r_t_T: jax.Array\n",
        "    a_t_T: jax.Array\n",
        "    done_t_T: jax.Array\n",
        "    logpa_t_TA: jax.Array\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class State:\n",
        "    update_idx: int\n",
        "    losses: list[float] = field(default_factory=list)\n",
        "    rewards: list[float] = field(default_factory=list)\n",
        "\n",
        "params = Hyperparams(\n",
        "    num_training_episodes=1000,\n",
        ")\n",
        "rngs = nnx.Rngs(default=params.seed)\n",
        "num_actions = env.action_space.n\n",
        "dim_in = env.observation_space.shape[0]\n",
        "\n",
        "policy_model = PolicyNetwork(dim_in, params.d_model, num_actions, params.n_layers, rngs)\n",
        "optimizer = nnx.Optimizer(qnet, optax.adamw(params.lr), wrt=nnx.Param)\n",
        "ckpt_dir = ocp.test_utils.erase_and_create_empty(params.ckpt_dir)\n",
        "checkpointer = ocp.StandardCheckpointer()\n",
        "\n",
        "state = State(0, 0, 0)\n",
        "\n",
        "\n",
        "def done_fn(state: State, params: Hyperparams):\n",
        "    return (state.update_idx >= params.max_num_updates)\n",
        "\n",
        "\n",
        "\n",
        "@struct.dataclass\n",
        "class Batch:\n",
        "    s_t_BD: np.ndarray\n",
        "    a_t_B: np.ndarray\n",
        "    r_t_B: np.ndarray\n",
        "    g_t_B: np.ndarray | None\n",
        "\n",
        "\n",
        "def compute_g(rewards: list[float], discount_rate: float) -> list[float]:\n",
        "    g = 0\n",
        "    g_t_B = []\n",
        "    for r in rewards[::-1]:\n",
        "        g = r + discount_rate * g\n",
        "        g_t_B.append(g)\n",
        "    return g_t_B[::-1]\n",
        "\n",
        "\n",
        "def collate(params: Hyperparameters, trajectory: list[Datum]) -> Batch:\n",
        "    states = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "    for d in trajectory:\n",
        "        states.append(d.s_t)\n",
        "        rewards.append(d.r_t)\n",
        "        actions.append(d.a_t)\n",
        "\n",
        "    g = compute_g(params, rewards)\n",
        "    states = np.array(states)\n",
        "    rewards = np.array(rewards)\n",
        "    actions = np.array(actions)\n",
        "    return Batch(\n",
        "        s_t_BD=states,\n",
        "        r_t_B=rewards,\n",
        "        a_t_B=actions\n",
        "        g_t_B=None,\n",
        "    )\n",
        "\n",
        "\n",
        "def unroll(params, env) -> TensorTrajectory:\n",
        "    trajectory = []\n",
        "    state, _ = env.reset()\n",
        "    for step in range(params.max_episode_length):\n",
        "        datum, state = play()\n",
        "        trajectory.append(datum)\n",
        "    return collate(params, trajectory)\n",
        "\n",
        "# train loop\n",
        "def loss_fn(model, s_t_D, a_t, g_t):\n",
        "    logits = model(s_t_D)\n",
        "    logp = jax.nn.log_softmax(logits)\n",
        "    logp_a_t = logp[a_t]\n",
        "    return -logp_a_t * g_t\n",
        "\n",
        "batched_loss_fn = jax.vmap(loss_fn, in_axes=(None, 0, 0, 0))\n",
        "\n",
        "for train_step in range(params.num_training_episodes):\n",
        "    batch = unroll(params, env)\n",
        "\n",
        "    def closure(model, rngs_for_closure):\n",
        "        batch_loss = batched_loss_fn(model, batch.s_t_BD, batch.a_t_B, batch.g_t_B)\n",
        "        return batch_loss.mean()\n",
        "\n",
        "    (loss, grads) = nnx.value_and_grad(closure)(model, rngs)\n",
        "    optimizer.update(grads)\n",
        "    state.losses.append(float(loss))\n",
        "    state.rewards.append(float(batch.r_t_B.sum()))\n",
        "\n",
        "    state.update_idx = train_step\n",
        "    done = done_fn(state, params)\n",
        "    if done or train_step % plot_interval == 0:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # plot losses and rewards\n",
        "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
        "        sns.lineplot(x=range(len(plot_loss)), y=plot_loss, ax=axes[0])\n",
        "        smooth_loss = gaussian_filter1d(plot_loss, sigma=2)\n",
        "        sns.lineplot(x=range(len(plot_loss)), y=smooth_loss, ax=axes[0], label=\"smooth\", legend=\"auto\")\n",
        "        axes[0].set_xlabel(\"Training step\")\n",
        "        axes[0].set_ylabel(\"Loss\")\n",
        "        axes[0].set_title(\"Training loss curve\")\n",
        "\n",
        "        sns.lineplot(x=range(len(plot_reward)), y=plot_reward, ax=axes[1])\n",
        "        smooth_reward = gaussian_filter1d(plot_reward, sigma=2)\n",
        "        sns.lineplot(x=range(len(plot_reward)), y=smooth_reward, ax=axes[1], label=\"smooth\", legend=\"auto\")\n",
        "\n",
        "        axes[1].set_xlabel(\"Training step\")\n",
        "        axes[1].set_ylabel(\"Reward\")\n",
        "        axes[1].set_title(\"Training reward curve\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    if done:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "LndM3nOj87OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JW-t0jac3rl3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}